{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\deniz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\deniz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\deniz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\deniz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\deniz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "import nltk \n",
    "nltk.download('punkt') \n",
    "nltk.download('brown') \n",
    "nltk.download('stopwords')\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "textTotal = open('RomeoJuliet.txt').read() \n",
    "blobTotal = TextBlob(textTotal) \n",
    "numChars = 1000\n",
    "text1000 = textTotal[0:numChars+1] \n",
    "blob1000 = TextBlob(text1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_words(list_words, numElementsRow):\n",
    "    for j in range (0,len(list_words),numElementsRow):\n",
    "        for i in range(j, j+numElementsRow):\n",
    "            if ( i >= len(list_words)):\n",
    "                break\n",
    "            print(i, '.', list_words[i], end=',')\n",
    "        print()\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of sentences= 3169\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "print('Count of sentences=', len(blobTotal.sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in the text that contain the word ‘Queen’ = 1\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "countSentences = 0 \n",
    "countSentencesWord=0 \n",
    "wordSearch = 'Queen' \n",
    "for s in blobTotal.sentences: \n",
    "    countSentences += 1 \n",
    "    if wordSearch in s: \n",
    "        countSentencesWord +=1\n",
    "print('Number of sentences in the text that contain the word ‘Queen’ =', countSentencesWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_Length = [] \n",
    "for s in blobTotal.sentences: \n",
    "    list_Length.append(len(s))\n",
    "    \n",
    "d = {'Sentence' : blobTotal.sentences,'Length': list_Length}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>(A, n, d,  , i, n,  , t, h, i, s,  , s, t, a, ...</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>(I, N, D, E, M, N, I, T, Y,  , -,  , Y, o, u, ...</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>(S, h, e,  , i, s,  , t, h, e,  , f, a, i, r, ...</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>(O, r, ,,  , i, f,  , I,  , l, i, v, e, ,,  , ...</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>(T, h, e,  , f, o, l, l, o, w, i, n, g,  , s, ...</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>(D, a, y, ,,  , n, i, g, h, t, ,,  , h, o, u, ...</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>(I,  , d, o,  , r, e, m, e, m, b, e, r,  , a, ...</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>(S, T, A, R, T, :,  , F, U, L, L,  , L, I, C, ...</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>(H, o, w, e, v, e, r, ,,  , i, f,  , y, o, u, ...</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>([, _, E, x, e, u, n, t, ., _, ], \\n, \\n, \\n, ...</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Length\n",
       "589   (A, n, d,  , i, n,  , t, h, i, s,  , s, t, a, ...     883\n",
       "3139  (I, N, D, E, M, N, I, T, Y,  , -,  , Y, o, u, ...     683\n",
       "588   (S, h, e,  , i, s,  , t, h, e,  , f, a, i, r, ...     667\n",
       "2411  (O, r, ,,  , i, f,  , I,  , l, i, v, e, ,,  , ...     554\n",
       "3087  (T, h, e,  , f, o, l, l, o, w, i, n, g,  , s, ...     533\n",
       "2165  (D, a, y, ,,  , n, i, g, h, t, ,,  , h, o, u, ...     526\n",
       "2693  (I,  , d, o,  , r, e, m, e, m, b, e, r,  , a, ...     503\n",
       "3061  (S, T, A, R, T, :,  , F, U, L, L,  , L, I, C, ...     471\n",
       "3102  (H, o, w, e, v, e, r, ,,  , i, f,  , y, o, u, ...     465\n",
       "3051  ([, _, E, x, e, u, n, t, ., _, ], \\n, \\n, \\n, ...     436"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "\n",
    "long = df.sort_values(by=['Length'], ascending=False)\n",
    "long.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>(U, p, .)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>(N, o, .)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>(N, o, .)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>(N, o, .)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>(H, a, !)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>(G, o, .)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>(1, ., D, .)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>(H, o, w, ?)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>(1, ., E, .)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118</th>\n",
       "      <td>(1, ., F, .)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentence  Length\n",
       "406      (U, p, .)       3\n",
       "1033     (N, o, .)       3\n",
       "150      (N, o, .)       3\n",
       "2603     (N, o, .)       3\n",
       "2523     (H, a, !)       3\n",
       "1400     (G, o, .)       3\n",
       "3080  (1, ., D, .)       4\n",
       "128   (H, o, w, ?)       4\n",
       "3085  (1, ., E, .)       4\n",
       "3118  (1, ., F, .)       4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "short = df.sort_values(by=['Length'], ascending=True)\n",
    "short.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Positive sentences: 662\n",
      "Total number of Negative sentences: 278\n",
      "Total number of Neutral sentences: 2229\n",
      "Total sum is equal. 3169 & 3169\n"
     ]
    }
   ],
   "source": [
    "#Analysis of Sentiments #1\n",
    "\n",
    "list_Polarity = [] \n",
    "for s in blobTotal.sentences: \n",
    "    list_Polarity.append(s.polarity)\n",
    "\n",
    "pos = 0\n",
    "neg = 0\n",
    "neutral = 0\n",
    "\n",
    "for i in range(0,len(list_Polarity)):\n",
    "    if list_Polarity[i] > 0:\n",
    "        pos = pos + 1\n",
    "    if list_Polarity[i] < 0:\n",
    "        neg = neg + 1\n",
    "    if list_Polarity[i] == 0:\n",
    "        neutral = neutral + 1\n",
    "        \n",
    "print('Total number of Positive sentences:', pos)\n",
    "print('Total number of Negative sentences:',neg)\n",
    "print('Total number of Neutral sentences:', neutral)\n",
    "    \n",
    "if len(blobTotal.sentences) == pos + neg + neutral:\n",
    "    print('Total sum is equal.' , len(blobTotal.sentences), '&', (pos + neg + neutral) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_Polarity = [] \n",
    "for s in blobTotal.sentences: \n",
    "    list_Polarity.append(s.polarity)\n",
    "    \n",
    "p = {'Sentence' : blobTotal.sentences,'Polarity': list_Polarity}\n",
    "df_p = pd.DataFrame(data=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>(H, a, p, p, i, l, y,  , m, e, t, ,,  , m, y, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>(W, e, l, c, o, m, e, ,,  , g, e, n, t, l, e, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>(B, e, a, u, t, i, f, u, l,  , t, y, r, a, n, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>(I,  , t, h, o, u, g, h, t,  , a, l, l,  , f, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>(A, y, ,,  , t, h, o, s, e,  , a, t, t, i, r, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Polarity\n",
       "2235  (H, a, p, p, i, l, y,  , m, e, t, ,,  , m, y, ...       1.0\n",
       "629   (W, e, l, c, o, m, e, ,,  , g, e, n, t, l, e, ...       1.0\n",
       "1711  (B, e, a, u, t, i, f, u, l,  , t, y, r, a, n, ...       1.0\n",
       "1552  (I,  , t, h, o, u, g, h, t,  , a, l, l,  , f, ...       1.0\n",
       "2380  (A, y, ,,  , t, h, o, s, e,  , a, t, t, i, r, ...       1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysis of Sentiments #2\n",
    "\n",
    "top_high = df_p.sort_values(by=['Polarity'], ascending=False)\n",
    "top_high.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>(Y, e, a, ,,  , i, s,  , t, h, e,  , w, o, r, ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>(T, h, e, r, e, â, €, ™, s,  , a,  , f, e, a, ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>(D, e, s, p, i, s, â, €, ™, d, ,,  , d, i, s, ...</td>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>(I,  , c, o, u, l, d,  , n, o, t,  , s, e, n, ...</td>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>(R, o, m, e, o, ,,  , c, o, m, e,  , f, o, r, ...</td>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Polarity\n",
       "1224  (Y, e, a, ,,  , i, s,  , t, h, e,  , w, o, r, ...      -1.0\n",
       "2409  (T, h, e, r, e, â, €, ™, s,  , a,  , f, e, a, ...      -1.0\n",
       "2565  (D, e, s, p, i, s, â, €, ™, d, ,,  , d, i, s, ...      -0.9\n",
       "2742  (I,  , c, o, u, l, d,  , n, o, t,  , s, e, n, ...      -0.9\n",
       "1771  (R, o, m, e, o, ,,  , c, o, m, e,  , f, o, r, ...      -0.9"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysis of Sentiments #3\n",
    "\n",
    "bottom = df_p.sort_values(by=['Polarity'], ascending=True)\n",
    "bottom.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(\"そしてこの状態で彼女は夜ごとにギャロップします\n",
       "恋人たちの頭脳を通して、そして彼らは愛を夢見ます。\n",
       "カーテシーをまっすぐに夢見るOâ€™ercourtiersâ€™膝。\n",
       "手数料をまっすぐに夢見ているOâ€™er弁護士â€™指。\n",
       "キスを真っ直ぐに夢見るOâ€™erladysâ€™唇、\n",
       "水ぶくれに悩まされている怒っているマブはどれですか？\n",
       "汚染されたお菓子で彼らの呼吸は次のとおりです。\n",
       "時々、彼女は礼儀正しい鼻をギャロップします、\n",
       "そして、彼がスーツの匂いを嗅ぐことを夢見ています。\n",
       "そしていつか彼女は什分の一の豚のしっぽを持って来る、\n",
       "眠っているときにパーソンの鼻をくすぐる、\n",
       "それから彼に別の恩恵を夢見ます：\n",
       "時々彼女は兵士の首を運転し、\n",
       "そして、彼が外国の喉を切ることを夢見ています、\n",
       "違反、ambuscados、スペインの刃、\n",
       "健康の5つの深さ;そしてアノン\n",
       "彼が開始して目覚める耳の太鼓。\n",
       "そして、このように怯えて、1つか2つの祈りを誓います、\n",
       "そしてまた眠ります。\")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "first = blobTotal.sentences[589]\n",
    "first.translate(to=\"ja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(\"補償-あなたは財団を補償し、保持することに同意します。\n",
       "商標権者、財団の代理人または従業員、誰でも\n",
       "ProjectGutenberg-tm電子作品のコピーを\n",
       "この合意に従い、およびに関連するすべてのボランティア\n",
       "Project Gutenberg-tmの制作、プロモーション、配布\n",
       "電子作品、すべての責任、費用、費用から無害、\n",
       "いずれかから直接的または間接的に発生する法定費用を含む\n",
       "あなたが行う、または発生させる次のこと：（a）これの配布\n",
       "またはProjectGutenberg-tmの作業、（b）変更、修正、または\n",
       "Project Gutenberg-tmの作品への追加または削除、および（c）\n",
       "あなたが引き起こす欠陥。\")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second = blobTotal.sentences[3139]\n",
    "second.translate(to=\"ja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['way', 'To', 'call', 'hers', 'exquisite'] 1.0\n",
      "['To', 'call', 'hers', 'exquisite', 'in'] 1.0\n",
      "['call', 'hers', 'exquisite', 'in', 'question'] 1.0\n",
      "['Your', 'plantain', 'leaf', 'is', 'excellent'] 1.0\n",
      "['plantain', 'leaf', 'is', 'excellent', 'for'] 1.0\n",
      "['leaf', 'is', 'excellent', 'for', 'that'] 1.0\n",
      "['is', 'excellent', 'for', 'that', 'BENVOLIO'] 1.0\n",
      "['excellent', 'for', 'that', 'BENVOLIO', 'For'] 1.0\n",
      "['well', 'that', 'now', 'shows', 'best'] 1.0\n",
      "['that', 'now', 'shows', 'best', 'ROMEO'] 1.0\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "\n",
    "c = 0\n",
    "for l in blobTotal.ngrams(n=5): \n",
    "    lString = str(l) \n",
    "    lBlob = TextBlob(lString) \n",
    "    if lBlob.polarity > 0.99 and c<10:\n",
    "        print(lBlob,lBlob.polarity) \n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "document1 = nlp(Path('RomeoJuliet.txt').read_text())\n",
    "document2 = nlp(Path('Hamlet.txt').read_text())\n",
    "document3 = nlp(Path('LesMiserable.txt').read_text(errors=\"ignore\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deniz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9708608317637386"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document1.similarity(document2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deniz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7707176950578497"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document1.similarity(document3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deniz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8329543088343044"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document2.similarity(document3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming, Lemmatization, Synonyms, Antonyms #1 #2 #3 #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anticip\n",
      "anticipation\n"
     ]
    }
   ],
   "source": [
    "#1 #2\n",
    "word1 = Word('anticipation')\n",
    "print(word1.stem())\n",
    "print(word1.lemmatize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry', 'furious', 'raging', 'tempestuous', 'wild'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "angry = Word('angry')\n",
    "synonyms = set() \n",
    "for synset in angry.synsets:\n",
    "    for lemma in synset.lemmas():\n",
    "        synonyms.add(lemma.name())\n",
    "synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('unangry.a.01.unangry')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "lemmas = angry.synsets[0].lemmas() \n",
    "lemmas[0].antonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readibility Assessment #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textatistic import Textatistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "document1 = open('RomeoJuliet.txt').read()\n",
    "document2 = open('Hamlet.txt').read()\n",
    "document3 = open('LesMiserable.txt', encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'char_count': 133712,\n",
       " 'word_count': 29278,\n",
       " 'sent_count': 3403,\n",
       " 'sybl_count': 35408,\n",
       " 'notdalechall_count': 6962,\n",
       " 'polysyblword_count': 1064,\n",
       " 'flesch_score': 95.78947092718265,\n",
       " 'fleschkincaid_score': 2.0359904316474005,\n",
       " 'gunningfog_score': 4.895085234481567,\n",
       " 'smog_score': 6.323466739387751,\n",
       " 'dalechall_score': 7.817933495505115}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readability1 = Textatistic(document1)\n",
    "readability1.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'char_count': 163048,\n",
       " 'word_count': 35237,\n",
       " 'sent_count': 4098,\n",
       " 'sybl_count': 43932,\n",
       " 'notdalechall_count': 8111,\n",
       " 'polysyblword_count': 1448,\n",
       " 'flesch_score': 92.63173771512857,\n",
       " 'fleschkincaid_score': 2.4751885234686313,\n",
       " 'gunningfog_score': 5.083160634661094,\n",
       " 'smog_score': 6.524908880107892,\n",
       " 'dalechall_score': 7.697598024212066}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readability2 = Textatistic(document2)\n",
    "readability2.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'char_count': 562037,\n",
       " 'word_count': 122869,\n",
       " 'sent_count': 7965,\n",
       " 'sybl_count': 157191,\n",
       " 'notdalechall_count': 25994,\n",
       " 'polysyblword_count': 6652,\n",
       " 'flesch_score': 82.94548596276992,\n",
       " 'fleschkincaid_score': 5.522374808844765,\n",
       " 'gunningfog_score': 8.33600414022729,\n",
       " 'smog_score': 8.349793125977707,\n",
       " 'dalechall_score': 7.742146380254521}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readability3 = Textatistic(document3)\n",
    "readability3.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
